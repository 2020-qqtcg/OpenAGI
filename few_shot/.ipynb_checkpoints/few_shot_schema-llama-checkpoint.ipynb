{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52235991-2c0f-455d-acaa-48d77bc7778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import os\n",
    "os.chdir('../')\n",
    "from general_dataset import GeneralDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from agi_utils import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46f833d5-40a7-4b56-8d76-df25583349b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_discriptions = txt_loader(\"./task_description.txt\")\n",
    "# task_idx = [0,21,61,105,110,120,10,35,62,107,115]\n",
    "test_task_idx = [2,3,10,15,20,35,45,55,65,70,90,106,107]\n",
    "test_dataloaders = []\n",
    "for i in test_task_idx:\n",
    "    dataset = GeneralDataset(i)\n",
    "    dataloader = DataLoader(dataset, batch_size=5)\n",
    "    test_dataloaders.append(dataloader)\n",
    "    \n",
    "test_tasks = [task_discriptions[i].strip() for i in test_task_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2748b625-77d6-4343-955c-2e4b453c59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_solution = []\n",
    "with open('./train_model_sequence.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[:50]:\n",
    "        train_solution.append(line)\n",
    "f.close()\n",
    "\n",
    "train_tasks = []\n",
    "with open('./train_task_description.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[:50]:\n",
    "        train_tasks.append(line)\n",
    "f.close()\n",
    "\n",
    "context = \"\"\n",
    "for i in range(len(train_tasks)):\n",
    "    steps = \"\"\n",
    "    for index,j in enumerate(train_solution[i].split(',')):\n",
    "        steps += \"Step \" + str(index+1) + \":\" + j.strip(\"\\n\") + \", \\n\"\n",
    "    cur = \"Problem: \" + train_tasks[i] +  \"Solution:\\n\" + steps\n",
    "    context += cur\n",
    "    \n",
    "# print(context + \"Problem: \" + test_tasks[0]+\"\\nSoltuion: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eb7c5d8-5040-42bb-8d2d-f42df0fa55b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0ed649f4c14a3face26eaaefb0f19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "# max_memory_mapping = {0: \"18GB\", 1: \"18GB\", 2: \"18GB\", 3: \"18GB\", 4: \"18GB\", 5: \"18GB\", 6: \"18GB\", 7: \"18GB\",}\n",
    "max_memory_mapping = {0: \"24GB\", 1: \"0GB\", 2: \"24GB\", 3: \"0GB\", 4: \"0GB\", 5: \"0GB\", 6: \"24GB\", 7: \"24GB\",}\n",
    "\n",
    "\n",
    "llama_tokenizer = transformers.LlamaTokenizer.from_pretrained(\"decapoda-research/llama-7b-hf\")\n",
    "llama = transformers.LlamaForCausalLM.from_pretrained(\"decapoda-research/llama-7b-hf\", \\\n",
    "                                                      # load_in_8bit=True,\\\n",
    "                                                      device_map='auto',\\\n",
    "                                                      max_memory = max_memory_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e22427-e6c2-43a2-aabc-9928dcda564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.utils import io\n",
    "from agi_utils import *\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from evaluate import load\n",
    "from torchvision import transforms\n",
    "from transformers import AutoModel, AutoFeatureExtractor\n",
    "from torchmetrics.multimodal import CLIPScore\n",
    "from combine_model_seq import SeqCombine\n",
    "\n",
    "\n",
    "clip_score = CLIPScore(model_name_or_path=\"openai/clip-vit-base-patch16\")\n",
    "\n",
    "\n",
    "# device_list = [\"cuda:1\",\"cuda:2\",\"cuda:3\",\"cuda:4\",\"cuda:5\",\"cuda:7\",\"cpu\"]\n",
    "device_list = [\"cuda:4\",\"cuda:6\",\"cpu\"]\n",
    "seqCombination = SeqCombine(device_list)\n",
    "\n",
    "\n",
    "# Load a pre-trained Vision Transformer model and its feature extractor\n",
    "vision_model_ckpt = \"nateraw/vit-base-beans\"\n",
    "vision_model = AutoModel.from_pretrained(vision_model_ckpt)\n",
    "vision_model.eval()\n",
    "vision_extractor = AutoFeatureExtractor.from_pretrained(vision_model_ckpt)\n",
    "\n",
    "f = transforms.ToPILImage()\n",
    "bertscore = load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "678c0389-f753-4dfc-98ac-fb27b37d6392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████▊         | 11/14 [13:53<03:10, 63.62s/it]Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "100%|███████████████████████████████████████████| 14/14 [16:18<00:00, 69.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished testing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rewards = []\n",
    "clips = []\n",
    "berts = []\n",
    "similairies = []\n",
    "\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2', device=\"cpu\")\n",
    "\n",
    "problem = test_tasks[1]\n",
    "\n",
    "\n",
    "for i, task_description in enumerate(tqdm(test_tasks)):\n",
    "    \n",
    "    task_rewards = []\n",
    "    with torch.no_grad():        \n",
    "        prompt = context + \"Problem: \" + task_description + \"\\nSoltuion: \"\n",
    "\n",
    "        llama_inputs = llama_tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        generated_ids = llama.generate(**llama_inputs, max_length=1000)\n",
    "        llama_outputs = llama_tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        llama_solution = llama_outputs[0].split(\"Problem: \")[1]\n",
    "        llama_solution = llama_solution.split(\"\\n\")\n",
    "        \n",
    "        llama_steps = []\n",
    "        for l,j in enumerate(llama_solution):\n",
    "            if j[0:4] == \"Step\":\n",
    "                llama_steps.append(llama_solution[l])\n",
    "\n",
    "        module_list = match_module_seq(llama_steps, sentence_model)\n",
    "\n",
    "\n",
    "    if len(module_list) > 0  and whole_module_seq_filter(module_list, test_task_idx[i]):\n",
    "        seqCombination.construct_module_seq(module_list)\n",
    "\n",
    "        for idx, batch in enumerate(test_dataloaders[i]):\n",
    "            if idx >=18:\n",
    "                break\n",
    "\n",
    "            inputs = list(batch['input'][0])\n",
    "            predictions = seqCombination.run_module_seq(inputs)\n",
    "\n",
    "            if 0<=test_task_idx[i]<=14:\n",
    "                outputs = list(batch['output'][0])\n",
    "                dist = image_similarity(predictions, outputs, vision_model, vision_extractor)\n",
    "                task_rewards.append(dist/100)\n",
    "            elif 15<=test_task_idx[i]<=104 or 107<=task_idx[i]<=154:\n",
    "                outputs = list(batch['output'][0])\n",
    "                f1 = np.mean(txt_eval(predictions, outputs, bertscore))\n",
    "                \n",
    "                task_rewards.append(f1)\n",
    "            else:\n",
    "                clip_score = score = clip_score(predictions, inputs)\n",
    "                task_rewards.append(clip_score.detach()/100)\n",
    "                \n",
    "        ave_task_reward = np.mean(task_rewards)    \n",
    "        \n",
    "        \n",
    "        seqCombination.close_module_seq()\n",
    "            \n",
    "    else:\n",
    "        ave_task_reward = 0\n",
    "        \n",
    "    if 0<=test_task_idx[i]<=14:\n",
    "        similairies.append(ave_task_reward)\n",
    "    elif 15<=test_task_idx[i]<=104 or 107<=test_task_idx[i]:\n",
    "        berts.append(ave_task_reward)\n",
    "    else:\n",
    "        clips.append(ave_task_reward)\n",
    "\n",
    "    rewards.append(ave_task_reward)     \n",
    "    \n",
    "\n",
    "print(\"Finished testing!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "186332c4-112e-4bfb-a876-f81a95734360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.17818482531441585, 0.0, 0.12727487522458275)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(clips), np.mean(berts), np.mean(similairies), np.mean(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c1969a-2876-4832-a4e2-f8769d5dd1c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
