{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52235991-2c0f-455d-acaa-48d77bc7778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import os\n",
    "os.chdir('../')\n",
    "from general_dataset import GeneralDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from agi_utils import *\n",
    "import torch\n",
    "import openai\n",
    "import numpy as np\n",
    "from IPython.utils import io\n",
    "from agi_utils import *\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from evaluate import load\n",
    "from torchvision import transforms\n",
    "from transformers import AutoModel, AutoFeatureExtractor\n",
    "from torchmetrics.multimodal import CLIPScore\n",
    "from combine_module_seq import SeqCombine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f833d5-40a7-4b56-8d76-df25583349b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "assign openagi data path \n",
    "\"\"\"\n",
    "data_path = \"YOUR_DATA_PATH\"\n",
    "\n",
    "task_discriptions = txt_loader(\"./task_description.txt\")\n",
    "# task_idx = [0,21,61,105,110,120,10,35,62,107,115]\n",
    "test_task_idx = [2,3,10,15,20,35,45,55,65,70,70,90,106,107]\n",
    "test_dataloaders = []\n",
    "for i in test_task_idx:\n",
    "    dataset = GeneralDataset(i, data_path)\n",
    "    dataloader = DataLoader(dataset, batch_size=5)\n",
    "    test_dataloaders.append(dataloader)\n",
    "    \n",
    "test_tasks = [task_discriptions[i].strip() for i in test_task_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779c1ed7-7003-4f45-96f9-9fd0a5f544f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_list = [\"cuda:1\",\"cuda:2\",\"cuda:3\",\"cuda:4\",\"cuda:5\",\"cuda:7\",\"cpu\"]\n",
    "device_list = [\"cuda:0\",\"cuda:1\",\"cpu\"]\n",
    "clip_score = CLIPScore(model_name_or_path=\"openai/clip-vit-base-patch16\")\n",
    "\n",
    "# Load a pre-trained Vision Transformer model and its feature extractor\n",
    "vit_ckpt = \"nateraw/vit-base-beans\"\n",
    "vit = AutoModel.from_pretrained(vit_ckpt)\n",
    "model.eval()\n",
    "vit_extractor = AutoFeatureExtractor.from_pretrained(vit_ckpt)\n",
    "\n",
    "f = transforms.ToPILImage()\n",
    "bertscore = load(\"bertscore\")\n",
    "\n",
    "\"\"\"\n",
    "assign openai api_key\n",
    "\"\"\"\n",
    "openai.api_key = \"YOUR_API_KEY\"\n",
    "\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2', device=\"cpu\")\n",
    "\n",
    "seqCombination = SeqCombine(device_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678c0389-f753-4dfc-98ac-fb27b37d6392",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "clips = []\n",
    "berts = []\n",
    "similairies = []\n",
    "#device for bert score\n",
    "device = \"cuda:3\"\n",
    "\n",
    "task_len = len(test_tasks)\n",
    "\n",
    "for i in range(task_len):\n",
    "    task_description = test_tasks[i]\n",
    "    task_rewards = []\n",
    "    with torch.no_grad():\n",
    "        completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                                                  messages=[{\"role\": \"user\", \\\n",
    "                                                             \"content\": \"Problem: \" +\\\n",
    "                                                             task_description +\\\n",
    "                                                             \"\\n What is its soltuion? Use 'Setp' to mark.\"}]\n",
    "                                                  )\n",
    "        gpt_output = completion.choices[0].message['content'].split('\\n')\n",
    "        gpt_steps = []\n",
    "        for l,j in enumerate(gpt_output):\n",
    "            if j[0:4] == \"Step\":\n",
    "                gpt_steps.append(gpt_output[l])\n",
    "        module_list_org = match_module_seq(gpt_steps, sentence_model)\n",
    "        x = module_list_org.split(\",\")\n",
    "        module_list = \",\".join(sorted(set(x), key=x.index))\n",
    "    \n",
    "\n",
    "    if len(module_list) > 0 and whole_module_seq_filter(module_list, test_task_idx[i]):\n",
    "        seqCombination.construct_module_seq(module_list)\n",
    "\n",
    "        for idx, batch in enumerate(test_dataloaders[i]): d\n",
    "            inputs = list(batch['input'][0])\n",
    "            predictions = seqCombination.run_module_seq(inputs)\n",
    "\n",
    "            if 0<=test_task_idx[i]<=14:\n",
    "                outputs = list(batch['output'][0])\n",
    "                dist = image_similarity(predictions, outputs, vit, vit_extractor)\n",
    "                task_rewards.append(dist/100)\n",
    "            elif 15<=test_task_idx[i]<=104 or 107<=task_idx[i]<=154:\n",
    "                outputs = list(batch['output'][0])\n",
    "                f1 = np.mean(txt_eval(predictions, outputs, bertscore, device=device))\n",
    "                \n",
    "                task_rewards.append(f1)\n",
    "            else:\n",
    "                score = clip_score(predictions, inputs)\n",
    "                task_rewards.append(score.detach()/100)\n",
    "                \n",
    "        ave_task_reward = np.mean(task_rewards)    \n",
    "        \n",
    "        \n",
    "        seqCombination.close_module_seq()\n",
    "            \n",
    "    else:\n",
    "        ave_task_reward = 0\n",
    "        \n",
    "    if 0<=test_task_idx[i]<=14:\n",
    "        similairies.append(ave_task_reward)\n",
    "    elif 15<=test_task_idx[i]<=104 or 107<=test_task_idx[i]<=184:\n",
    "        berts.append(ave_task_reward)\n",
    "    else:\n",
    "        clips.append(ave_task_reward)\n",
    "\n",
    "    rewards.append(ave_task_reward)     \n",
    "    \n",
    "\n",
    "print(\"Finished testing!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf8df8-ba6c-4990-9443-774cee6ebbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(clips), np.mean(berts), np.mean(similairies), np.mean(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950d9b54-7d6f-4426-9e2c-69fa6e09dfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceb1ffa-7646-4ccf-bfd5-da2a97a5dedc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
