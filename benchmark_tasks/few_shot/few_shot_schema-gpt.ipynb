{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52235991-2c0f-455d-acaa-48d77bc7778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import os\n",
    "os.chdir('../')\n",
    "from general_dataset import GeneralDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from agi_utils import *\n",
    "import openai\n",
    "import numpy as np\n",
    "from IPython.utils import io\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from evaluate import load\n",
    "from torchvision import transforms\n",
    "from transformers import AutoModel, AutoFeatureExtractor\n",
    "from torchmetrics.multimodal import CLIPScore\n",
    "from combine_model_seq import SeqCombine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f833d5-40a7-4b56-8d76-df25583349b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "assign openagi data path \n",
    "\"\"\"\n",
    "data_path = \"./openagi_data/\"\n",
    "\n",
    "task_discriptions = txt_loader(\"./task_description.txt\")\n",
    "# task_idx = [0,21,61,105,110,120,10,35,62,107,115]\n",
    "test_task_idx = [2,3,10,15,20,35,45,55,65,70,70,90,106,107]\n",
    "test_dataloaders = []\n",
    "for i in test_task_idx:\n",
    "    dataset = GeneralDataset(i, data_path)\n",
    "    dataloader = DataLoader(dataset, batch_size=5)\n",
    "    test_dataloaders.append(dataloader)\n",
    "    \n",
    "test_tasks = [task_discriptions[i].strip() for i in test_task_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2748b625-77d6-4343-955c-2e4b453c59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_solution = []\n",
    "with open('./train_model_sequence.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[:50]:\n",
    "        train_solution.append(line)\n",
    "f.close()\n",
    "\n",
    "train_tasks = []\n",
    "with open('./train_task_description.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[:50]:\n",
    "        train_tasks.append(line)\n",
    "f.close()\n",
    "\n",
    "context = \"\"\n",
    "for i in range(len(train_tasks)):\n",
    "    steps = \"\"\n",
    "    for index,j in enumerate(train_solution[i].split(',')):\n",
    "        steps += \"Step \" + str(index+1) + \":\" + j.strip(\"\\n\") + \", \\n\"\n",
    "    cur = \"Problem: \" + train_tasks[i] +  \"Solution:\\n\" + steps\n",
    "    context += cur\n",
    "    \n",
    "# print(context + \"Problem: \" + test_tasks[0]+\"\\nSoltuion: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678c0389-f753-4dfc-98ac-fb27b37d6392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_list = [\"cuda:1\",\"cuda:2\",\"cuda:3\",\"cuda:4\",\"cuda:5\",\"cuda:7\",\"cpu\"]\n",
    "device_list = [\"cuda:3\",\"cuda:4\",\"cpu\"]\n",
    "seqCombination = SeqCombine(device_list)\n",
    "\n",
    "\n",
    "# Load a pre-trained Vision Transformer model and its feature extractor\n",
    "vit_ckpt = \"nateraw/vit-base-beans\"\n",
    "vit = AutoModel.from_pretrained(vit_ckpt)\n",
    "vit.eval()\n",
    "vit_extractor = AutoFeatureExtractor.from_pretrained(vit_ckpt)\n",
    "\n",
    "f = transforms.ToPILImage()\n",
    "bertscore = load(\"bertscore\")\n",
    "clip_score = CLIPScore(model_name_or_path=\"openai/clip-vit-base-patch16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6ea6c6-c2f9-438a-9769-59ae5dc85c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "assign openai api_key\n",
    "\"\"\"\n",
    "openai.api_key = \"YOUR_API_KEY\"\n",
    "\n",
    "device = \"cuda:4\"\n",
    "rewards = []\n",
    "clips = []\n",
    "berts = []\n",
    "similairies = []\n",
    "\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2', device=\"cpu\")\n",
    "\n",
    "problem = test_tasks[1]\n",
    "\n",
    "\n",
    "for i, task_description in enumerate(tqdm(test_tasks)):\n",
    "    \n",
    "    task_rewards = []\n",
    "    with torch.no_grad():\n",
    "        completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\\\n",
    "                                                  messages=[{\"role\": \"user\",\\\n",
    "                                                             \"content\": context +\\\n",
    "                                                             \"Problem: \" +\\\n",
    "                                                             task_description +\\\n",
    "                                                             \"\\nSoltuion: \"}]\n",
    "                                                  )\n",
    "        gpt_output = completion.choices[0].message['content'].split('\\n')\n",
    "        gpt_steps = []\n",
    "        for l,j in enumerate(gpt_output):\n",
    "            if j[0:4] == \"Step\":\n",
    "                gpt_steps.append(gpt_output[l])\n",
    "        module_list = match_module_seq(gpt_steps, sentence_model)\n",
    "    # print(module_list)\n",
    "    # break\n",
    "\n",
    "\n",
    "    if len(module_list) > 0 and whole_module_seq_filter(module_list, test_task_idx[i]):\n",
    "        seqCombination.construct_module_seq(module_list)\n",
    "\n",
    "        for idx, batch in enumerate(test_dataloaders[i]):\n",
    "            inputs = list(batch['input'][0])\n",
    "            predictions = seqCombination.run_module_seq(inputs)\n",
    "\n",
    "            if 0<=test_task_idx[i]<=14:\n",
    "                outputs = list(batch['output'][0])\n",
    "                dist = image_similarity(predictions, outputs, vit, vit_extractor)\n",
    "                task_rewards.append(dist/100)\n",
    "            elif 15<=test_task_idx[i]<=104 or 107<=task_idx[i]<=154:\n",
    "                outputs = list(batch['output'][0])\n",
    "                f1 = np.mean(txt_eval(predictions, outputs, bertscore, device=device))\n",
    "                \n",
    "                task_rewards.append(f1)\n",
    "            else:\n",
    "                score = score = clip_score(predictions, inputs)\n",
    "                task_rewards.append(score.detach()/100)\n",
    "                \n",
    "        ave_task_reward = np.mean(task_rewards)    \n",
    "        \n",
    "        \n",
    "        seqCombination.close_module_seq()\n",
    "            \n",
    "    else:\n",
    "        ave_task_reward = 0\n",
    "        \n",
    "    if 0<=test_task_idx[i]<=14:\n",
    "        similairies.append(ave_task_reward)\n",
    "    elif 15<=test_task_idx[i]<=104 or 107<=test_task_idx[i]:\n",
    "        berts.append(ave_task_reward)\n",
    "    else:\n",
    "        clips.append(ave_task_reward)\n",
    "\n",
    "    rewards.append(ave_task_reward)     \n",
    "    \n",
    "\n",
    "print(\"Finished testing!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186332c4-112e-4bfb-a876-f81a95734360",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(clips), np.mean(berts), np.mean(similairies), np.mean(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27491300-85b6-42dc-abfe-983925075dab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
